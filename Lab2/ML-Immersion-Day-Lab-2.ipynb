{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Immersion Day \n",
    "# Data preparation\n",
    "\n",
    "This document contains the documented code to do the data preparation part of the AWS Machine Learning Immersion Day.\n",
    "\n",
    "Before running the code, make sure to read and try to understand what the code is doing.\n",
    "\n",
    "Execute the code by clicking the Run button in the toolbar above or pressing Shift + Return, both while having the cell containing the code in focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go!\n",
    "\n",
    "Begin with importing dependencies and setting up some base variables that later code will be referring to.\n",
    "\n",
    "*Don't forget to change the your_initials value to the initials you used in Lab1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_initials = 'put-your-initials-here'\n",
    "\n",
    "bucket = your_initials + '-ml-id-lab'\n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_deserializer\n",
    "  \n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the code is running, there will be a bracketed asterisk showing to the left of the code **[*]**. Once finished, the asterisk will be replaced with a number showing the order of execution within the current notebook document's state.\n",
    "\n",
    "Next, download one of the data files used in Lab1 to the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file('movielens-data/u.data/data.csv', 'u.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file downloaded is a compacted version if the data explored in Lab1. This is the description of the file:\n",
    "\n",
    "> ```text\n",
    "> u.data \n",
    ">\n",
    "> The full u data set, 100000 ratings by 943 users on 1682 items.\n",
    "> Each user has rated at least 20 movies.  Users and items are numbered consecutively from 1.  The data is randomly ordered. This is a tab separated list of:\n",
    "> user id | item id | rating | timestamp\n",
    "> The time stamps are unix seconds since 1/1/1970 UTC```\n",
    "\n",
    "While this is an intuitive and realtively compact way of storing the information, it is not optimal for training factorisation machine models. In order to have good training data, this data needs to be split and transformed.\n",
    "\n",
    "First, split the data into one larger training part and one smaller testing part (10 samples per user).\n",
    "\n",
    "At the end of running the code, the two rating counters will be printed to an output that is added below the cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbUsers=943\n",
    "nbMovies=1682\n",
    "nbFeatures=nbUsers+nbMovies\n",
    "\n",
    "# Pick 10 ratings per user and save as test data set ua.test\n",
    "# Save the rest as training data set ua.base\n",
    "!rm -f ua.base || touch ua.base\n",
    "!rm -f ua.test || touch ua.test\n",
    "  \n",
    "# Extract 10 samples per user into test data\n",
    "maxRatingsByUser = 10\n",
    "# Keep track of how many ratings have been extracted, initalize to 0 \n",
    "testRatingsByUser = {}\n",
    "for userId in range(nbUsers):\n",
    "    testRatingsByUser[str(userId)]=0\n",
    "\n",
    "  \n",
    "with open('u.data','r') as f, open('ua.base','w') as uabase, open('ua.test','w') as uatest:\n",
    "    filedata=csv.reader(f,delimiter='\\t')\n",
    "    next(filedata, None) # skip headers\n",
    "    uabasewriter = csv.writer(uabase, delimiter='\\t')\n",
    "    uatestwriter = csv.writer(uatest, delimiter='\\t')\n",
    "    nbRatingsTrain=0\n",
    "    nbRatingsTest=0\n",
    "    # For every rating line in file\n",
    "    for userId,movieId,rating,timestamp in filedata:\n",
    "        if testRatingsByUser[str(int(userId)-1)] < maxRatingsByUser:\n",
    "            # Write to test data \n",
    "            uatestwriter.writerow([userId,movieId,rating,timestamp])\n",
    "            testRatingsByUser[str(int(userId)-1)] = testRatingsByUser[str(int(userId)-1)] + 1\n",
    "            nbRatingsTest=nbRatingsTest+1\n",
    "        else:\n",
    "            # Write to training data\n",
    "            uabasewriter.writerow([userId,movieId,rating,timestamp]) \n",
    "            nbRatingsTrain=nbRatingsTrain+1\n",
    "            \n",
    "print(\"Train data ratings counter: %s\" % (nbRatingsTrain))\n",
    "print(\"Test data ratings counter: %s\" % (nbRatingsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the partitioned data looks good by printing the first 10 rows of each file. \n",
    "> Notice that the exclamation mark starting each line in this snippets means that the line is to be executed as a shell command, rather than as python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Training data:\"\n",
    "!head -10 ua.base\n",
    "!echo \"Testing data:\"\n",
    "!head -10 ua.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should show ten lines containing four columns for each file. You may notice that the training data seems to have reoccuring lines contains the same value in the first column (user_id). These types of regularities in the training data can lead to suboptimal training.\n",
    "\n",
    "Create a new file containing shuffled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shuf ua.base -o ua.base.shuffled\n",
    "!head -10 ua.base.shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have two sets of source data, but need to process them more before training and testing a factorization machine model. What is needed for each of the sets is:\n",
    "\n",
    "- Create a one-hot encoded sparse matrix holding **features** (input to the model)\n",
    "- Create a **label** array (the expected output from the model)\n",
    "- Serialize both of the above into protobuf format and write them to the S3 bucket.\n",
    "\n",
    "Define a function **loadDataset** that loads a dataset and returns a one-hot encoded feature sparse matrix and a label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, lines, columns):\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    # Labels are stored in a vector\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter='\\t')\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(nbUsers)+int(movieId)-1] = 1\n",
    "            if int(rating) >= 4:\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "            line=line+1\n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to verify some properties of the returned data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = loadDataset('ua.base.shuffled', nbRatingsTrain, nbFeatures)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "assert X_train.shape == (nbRatingsTrain, nbFeatures)\n",
    "assert Y_train.shape == (nbRatingsTrain, )\n",
    "nonzero_labels = np.count_nonzero(Y_train)\n",
    "print(\"Training labels: %d ones, %d zeros\" % (nonzero_labels, nbRatingsTrain-nonzero_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = loadDataset('ua.test', nbRatingsTest, nbFeatures)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "assert X_test.shape  == (nbRatingsTest, nbFeatures)\n",
    "assert Y_test.shape  == (nbRatingsTest, )\n",
    "nonzero_labels = np.count_nonzero(Y_test)\n",
    "print(\"Test labels: %d ones, %d zeros\" % (nonzero_labels, nbRatingsTest-nonzero_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will serialise these structures in protobuf format on S3. Start by defining target names  for the S3 objects, and a function to do the serialisation and return the path to the object on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sagemaker/recommender-fm'\n",
    "\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, write the data by calling the function for the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)  \n",
    "print(\"Training data at: %s\" % (train_data))\n",
    "\n",
    "test_data  = writeDatasetToProtobuf(X_test, Y_test, bucket, test_prefix, test_key)    \n",
    "print(\"Testing data at: %s\" % (test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see obejcts at these paths in the S3 console. Note how efficiently the sparse matrix is stored, only 5.8 MB for the training set.\n",
    "\n",
    "You have now finished preparing data and are ready to start training your model. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Model Training\n",
    "In this part of the lab, you will now invoke Amazon Sagemaker training and testing from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "  \n",
    "containers = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-northeast-1': '351501993468.dkr.ecr.ap-northeast-1.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-northeast-2': '835164637446.dkr.ecr.ap-northeast-2.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-southeast-2': '712309505854.dkr.ecr.ap-southeast-2.amazonaws.com/factorization-machines:latest',\n",
    "             'eu-central-1': '664544806723.dkr.ecr.eu-central-1.amazonaws.com/factorization-machines:latest',\n",
    "             'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/factorization-machines:latest'}\n",
    "  \n",
    "print(\"The trained model will be written to: %s\" % (output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a factorization machine Estimator object and set the hyperparameters to be used when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                  get_execution_role(), \n",
    "                                  train_instance_count=1, \n",
    "                                  train_instance_type='ml.c4.xlarge',\n",
    "                                  output_path=output_prefix,\n",
    "                                  sagemaker_session=sagemaker.Session())\n",
    "  \n",
    "fm.set_hyperparameters(feature_dim=nbFeatures,\n",
    "                     predictor_type='binary_classifier',\n",
    "                     mini_batch_size=1000,\n",
    "                     num_factors=64,\n",
    "                     epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, invoke training on Amazon Sagemaker. While the training is running, Amazon Sagemaker will continuously produce output below the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular training job should take 4-5 minutes, the training is finished when you see  `Billable seconds: ###` at the end of the output.\n",
    " \n",
    "You can also monitor progress of the training in the Amazon Sagemaker console by selecting **Training jobs** in the main menu.\n",
    "\n",
    "The trained model will be written to the path defined by **output_prefix**, you can verify that there is a **model.tar.gz** object in the S3 console.\n",
    "\n",
    "You have now trained your model and are ready to start using it.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deploy Endpoint and Test Inference\n",
    "\n",
    "In the last section of this lab you will deploy a development endpoint and test run some inferences of your model. **Do not start this section unless your training job from the earlier step has status Completed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start up an endpoint instance, you can monitor progress through the notebook, or on the Amazon Sagemaker console by selection **Endpoints** in the menu.\n",
    "\n",
    "Next, configure serialization options for the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        js['instances'].append({'features': row.tolist()})\n",
    "    #print js\n",
    "    return json.dumps(js)\n",
    "  \n",
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to call the endpoint with ten test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fm_predictor.predict(X_test[1000:1010].toarray())\n",
    "print(\"Prediction (Score) Expected\")\n",
    "for index, p in enumerate(result['predictions']):\n",
    "    print(\"%10.2f %6.2f  %8.2f\" % (p['predicted_label'], p['score'], Y_test[1000 + index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the cell will produce a text table with three columns: **Prediction** and **Score** (from the model) and **Expected**. If the model works well, Prediction and Expected values should match on each row.\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You have now deployed and tested you recommendation ML model and are finished with Lab 2.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
